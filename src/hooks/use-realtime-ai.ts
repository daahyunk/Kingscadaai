// ------------------------------------------
// KingSCADA AI â€” ê·¹ì•ˆì •í™” ë²„ì „ useRealtimeAI
//  - STT í•­ìƒ ìˆ˜ì‹ í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” "ì‚¬ëŒì´ ë§í•œ ë¬¸ì¥"ë§Œ í†µê³¼
//  - ì‹œì‘ 1ì´ˆ ë¬´ì¡°ê±´ ë²„ë¦¬ê¸°
//  - Silence Gate (í˜¸í¡/í‚¤ë³´ë“œ/ë°”ëŒ/ì§§ì€ ìŒì ˆ â†’ ë¬´ì‹œ)
//  - AI ë§í•˜ëŠ” ë™ì•ˆ STT ìë™ ì°¨ë‹¨
//  - AI ì—ì½” ì°¨ë‹¨ + ì¶”ì„ìƒˆ í•„í„°
// ------------------------------------------

import { useRef, useState } from "react";

export type Lang = "ko" | "en" | "zh";

export interface RealtimeMessageCallback {
  onUserMessage?: (text: string) => void;
  onAIMessage?: (text: string) => void;
  onEquipmentDetail?: (equipmentId: string) => void;
}

export function useRealtimeAI() {
  const [isConnecting, setIsConnecting] = useState(false);
  const [isConnected, setIsConnected] = useState(false);

  const peerRef = useRef<RTCPeerConnection | null>(null);
  const channelRef = useRef<RTCDataChannel | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  const messageCallbackRef = useRef<RealtimeMessageCallback>({});
  const currentResponseRef = useRef("");
  const lastAssistantTextRef = useRef("");

  // â­ ì½œ ì‹œì‘ ì‹œê°„
  const callStartTimeRef = useRef<number>(0);

  // â­ AIê°€ ë§í•˜ëŠ” ì¤‘ì¸ì§€ ì—¬ë¶€
  const isAssistantSpeakingRef = useRef(false);

  // ----------------------------------------------------
  // Silence Gate â€” ì§§ì€ ì¡ìŒ/ëª¨ìŒ/ììŒ/í˜¸í¡ ë¬´ì¡°ê±´ ì œê±°
  // ----------------------------------------------------
  function isSilence(text: string): boolean {
    if (!text) return true;

    // 1ê¸€ì ë˜ëŠ” 2ê¸€ì â†’ ëŒ€ë¶€ë¶„ ì¡ìŒ
    if (text.length <= 2) return true;

    // ììŒ/ëª¨ìŒ ì—°ì†
    if (/^[ã„±-ã…ã…-ã…£]+$/.test(text)) return true;

    // ì˜ì–´ 1~2ê¸€ì
    if (/^[a-zA-Z]{1,2}$/.test(text)) return true;

    // Whisper ê³ ì§ˆ hallucination
    if (
      text.includes("MBC") ||
      text.includes("ë‰´ìŠ¤") ||
      text.includes("ì´ë•ì˜")
    )
      return true;

    return false;
  }

  // ----------------------------------------------------
  // ì‚¬ëŒì´ ì‹¤ì œ ë§í•œ ë¬¸ì¥ì¸ì§€ ê²€ì‚¬í•˜ëŠ” ê°•ë ¥ í•„í„°
  // ----------------------------------------------------
  function isHumanSpeech(text: string): boolean {
    if (!text) return false;

    // ê¸°ë³¸ ê¸¸ì´ ì¡°ê±´
    if (text.length < 3) return false;

    // ììŒ/ëª¨ìŒë§Œ â†’ ì¡ìŒ
    if (/^[ã„±-ã…ã…-ã…£]+$/.test(text)) return false;

    // ì˜ì–´ ì¡ìŒ
    if (/^[a-zA-Z]{1,2}$/.test(text)) return false;

    // bye/thankyou ë“± STT í™˜ê°
    if (/^(bye|byebye|thank|thankyou)$/i.test(text)) return false;

    // ìì—°ì–´ í¬í•¨ ì‹œ â†’ ì‚¬ëŒ ë°œí™”ë¡œ ì¸ì •
    if (/[ê°€-í£]/.test(text)) return true;
    if (/[a-zA-Z]/.test(text)) return true;

    return false;
  }

  // ----------------------------------------------------
  // ê¸°ì¡´ ì—ì½”/ì¶”ì„ìƒˆ í•„í„°
  // ----------------------------------------------------
  function shouldIgnoreTranscript(
    transcript: string,
    lastAssistantText: string
  ) {
    const t = transcript.trim();
    if (!t) return true;

    // ì¶”ì„ìƒˆ
    const noiseWords = ["ìŒ", "ì–´", "ì•„"];
    if (noiseWords.includes(t)) return true;

    // AI ì§ì „ ë°œí™”ì™€ ìœ ì‚¬í•˜ë©´ ì—ì½”
    if (lastAssistantText) {
      const normA = lastAssistantText.replace(/\s+/g, "");
      const normT = t.replace(/\s+/g, "");

      if (!normT) return true;

      if (
        normA.includes(normT) ||
        normT.includes(normA.slice(0, Math.max(5, Math.min(30, normA.length))))
      ) {
        return true;
      }
    }

    return false;
  }

  // ----------------------------------------------------
  // startCall
  // ----------------------------------------------------
  async function startCall(
    lang: Lang = "ko",
    callbacks?: RealtimeMessageCallback,
    equipmentState?: Record<string, number>
  ) {
    if (isConnecting || isConnected) return;

    messageCallbackRef.current = callbacks || {};
    currentResponseRef.current = "";
    lastAssistantTextRef.current = "";
    callStartTimeRef.current = Date.now();
    isAssistantSpeakingRef.current = false;

    setIsConnecting(true);
    console.log("[Realtime] startCall");

    try {
      const API_BASE_URL = (import.meta.env.VITE_API_URL || "").trim();
      if (!API_BASE_URL) throw new Error("VITE_API_URL not set");

      // ------------------- ì„¸ì…˜ ë°œê¸‰ -------------------
      const params = new URLSearchParams();
      if (equipmentState) {
        for (const [k, v] of Object.entries(equipmentState)) {
          params.append(k, String(v));
        }
      }

      const sessionUrl = `${API_BASE_URL}/api/session/${lang}${
        params.toString() ? `?${params.toString()}` : ""
      }`;

      const sessionRes = await fetch(sessionUrl);
      const sessionData = await sessionRes.json();
      const EPHEMERAL_KEY = sessionData?.client_secret?.value;
      if (!EPHEMERAL_KEY) throw new Error("No ephemeral key");

      // ------------------- ë§ˆì´í¬ -------------------
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: false, // ğŸŸ¢ autoGain ë„ê¸° = í™˜ê° ì¤„ì–´ë“¦
          channelCount: 1,
        },
      });
      streamRef.current = stream;

      // ------------------- Peer -------------------
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
      });
      peerRef.current = pc;

      stream.getTracks().forEach((t) => pc.addTrack(t, stream));

      // ------------------- AI ìŒì„± ìˆ˜ì‹  -------------------
      const audio = new Audio();
      audio.autoplay = true;
      audioRef.current = audio;

      pc.ontrack = (e) => {
        const [remoteStream] = e.streams;
        if (remoteStream) audio.srcObject = remoteStream;
      };

      pc.onconnectionstatechange = () => {
        if (["failed", "disconnected", "closed"].includes(pc.connectionState)) {
          endCall();
        }
      };

      // ------------------- DataChannel -------------------
      const channel = pc.createDataChannel("response");
      channelRef.current = channel;

      channel.onopen = () => {
        channel.send(JSON.stringify({ type: "response.create" }));
      };

      channel.onmessage = (ev) => {
        try {
          const msg = JSON.parse(ev.data);

          // ---------------- AI ìŒì„± â†’ delta ----------------
          if (msg.type === "response.audio.delta") {
            isAssistantSpeakingRef.current = true;
          }

          // ---------------- AI ìŒì„± â†’ done ----------------
          if (msg.type === "response.audio.done") {
            setTimeout(() => {
              isAssistantSpeakingRef.current = false;
            }, 150);
          }

          // ---------------- AI í…ìŠ¤íŠ¸ ----------------
          if (msg.type === "response.audio_transcript.delta") {
            currentResponseRef.current += msg.delta ?? "";
          }

          if (msg.type === "response.audio_transcript.done") {
            const full = currentResponseRef.current.trim();
            currentResponseRef.current = "";

            if (!full) return;

            const match = full.match(/\[EQUIPMENT_DETAIL:(\w+)\]/);
            const equipId = match?.[1] || null;
            const clean = full.replace(/\[EQUIPMENT_DETAIL:\w+\]/g, "").trim();

            lastAssistantTextRef.current = clean;
            messageCallbackRef.current.onAIMessage?.(clean);
            if (equipId)
              messageCallbackRef.current.onEquipmentDetail?.(equipId);
          }

          // ---------------- ì‚¬ìš©ì STT ----------------
          if (
            msg.type === "conversation.item.input_audio_transcription.completed"
          ) {
            const text = msg.transcript?.trim();
            if (!text) return;

            // â‘  ì²« 1ì´ˆ ë¬´ì‹œ
            if (Date.now() - callStartTimeRef.current < 1000) {
              return;
            }

            // â‘¡ AI ë§í•  ë•Œ ë¬´ì¡°ê±´ ì°¨ë‹¨
            if (isAssistantSpeakingRef.current) {
              return;
            }

            // â‘¢ Silence Gate
            if (isSilence(text)) {
              return;
            }

            // â‘£ ìì—°ì–´(ì‚¬ëŒ ë°œí™”) ê²€ì¦
            if (!isHumanSpeech(text)) {
              return;
            }

            // â‘¤ ì—ì½”/ì¶”ì„ìƒˆ
            if (shouldIgnoreTranscript(text, lastAssistantTextRef.current)) {
              return;
            }

            // ---------------- ìµœì¢… í†µê³¼ ----------------
            messageCallbackRef.current.onUserMessage?.(text);
          }
        } catch (e) {
          console.error("onmessage parse error", e);
        }
      };

      // ------------------- SDP -------------------
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      const sdpRes = await fetch(
        `https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2025-06-03`,
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${EPHEMERAL_KEY}`,
            "Content-Type": "application/sdp",
          },
          body: offer.sdp || "",
        }
      );

      const answerSdp = await sdpRes.text();
      await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

      setIsConnected(true);
      setIsConnecting(false);
    } catch (err) {
      console.error("startCall error", err);
      endCall();
    } finally {
      setIsConnecting(false);
    }
  }

  // ----------------------------------------------------
  // endCall
  // ----------------------------------------------------
  function endCall() {
    try {
      channelRef.current?.close();
      peerRef.current?.getSenders().forEach((s) => s.track?.stop());
      peerRef.current?.close();

      audioRef.current?.pause();
      if (audioRef.current) audioRef.current.srcObject = null;

      streamRef.current?.getTracks().forEach((t) => t.stop());
    } catch {}

    channelRef.current = null;
    peerRef.current = null;
    audioRef.current = null;
    streamRef.current = null;

    setIsConnected(false);
    setIsConnecting(false);
  }

  return { startCall, endCall, isConnecting, isConnected };
}
