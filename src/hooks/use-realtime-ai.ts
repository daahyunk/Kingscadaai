// ------------------------------------------
// KingSCADA AI â€” ì•ˆì •í™” ë²„ì „ useRealtimeAI
//  - STT í•­ìƒ ìˆ˜ì‹ 
//  - ì‹œì‘ 1ì´ˆ ë¬´ì¡°ê±´ ë²„ë¦¬ê¸° (ì´ˆê¸° í™˜ê° ì œê±°)
//  - Silence Gate (ê·¹ì €ìŒ/í˜¸í¡/ë°”ëŒ â†’ ë¬´ì‹œ)
//  - AIê°€ ìê¸° ë§ ë“£ê³  ë°˜ë³µí•˜ëŠ” ì—ì½” ìµœì†Œí™”
//  - ë¼ì–´ë“¤ê¸°(ë°”ë¡œ ë§í•˜ê¸°) ì§€ì›
// ------------------------------------------

import { useRef, useState } from "react";

export type Lang = "ko" | "en" | "zh";

export interface RealtimeMessageCallback {
  onUserMessage?: (text: string) => void;
  onAIMessage?: (text: string) => void;
  onEquipmentDetail?: (equipmentId: string) => void;
}

export function useRealtimeAI() {
  const [isConnecting, setIsConnecting] = useState(false);
  const [isConnected, setIsConnected] = useState(false);

  const peerRef = useRef<RTCPeerConnection | null>(null);
  const channelRef = useRef<RTCDataChannel | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  const messageCallbackRef = useRef<RealtimeMessageCallback>({});
  const currentResponseRef = useRef("");
  const lastAssistantTextRef = useRef("");

  // â­ NEW: ì½œ ì‹œì‘ ì‹œê°„
  const callStartTimeRef = useRef<number>(0);

  // --------------------------
  // Silence Gate (ë¬´ìŒÂ·ì¡ìŒ í•„í„°)
  // --------------------------
  function isSilence(text: string): boolean {
    if (!text) return true;

    // ë„ˆë¬´ ì§§ì€ ë¬¸ì(1~2ê¸€ì) â†’ ëŒ€ë¶€ë¶„ ë…¸ì´ì¦ˆ
    if (text.length <= 1) return true;

    // í•œ ë‹¨ì–´ + ììŒ ë¹„ìœ¨ ë†’ì€ ê²½ìš°
    if (/^[a-zA-Z]{1,2}$/.test(text)) return true;

    // ìœ ëª…í•œ hallucination íŒ¨í„´
    if (
      text.includes("MBC") ||
      text.includes("ë‰´ìŠ¤") ||
      text.includes("ì´ë•ì˜")
    )
      return true;

    return false;
  }

  // --------------------------
  // í…ìŠ¤íŠ¸ ê¸°ë°˜ STT í•„í„° (ê¸°ì¡´)
  // --------------------------
  function shouldIgnoreTranscript(
    transcript: string,
    lastAssistantText: string
  ): boolean {
    const t = transcript.trim();
    if (!t) return true;

    // 1) ì¶”ì„ìƒˆ
    const noiseWords = ["ìŒ", "ì–´", "ì•„"];
    if (noiseWords.includes(t)) return true;

    // 2) AI ì—ì½” ë°©ì§€
    if (lastAssistantText) {
      const normA = lastAssistantText.replace(/\s+/g, "");
      const normT = t.replace(/\s+/g, "");
      if (!normT) return true;

      if (
        normA.includes(normT) ||
        normT.includes(normA.slice(0, Math.max(5, Math.min(30, normA.length))))
      ) {
        return true;
      }
    }

    return false;
  }

  // --------------------------
  // startCall
  // --------------------------
  async function startCall(
    lang: Lang = "ko",
    callbacks?: RealtimeMessageCallback,
    equipmentState?: Record<string, number>
  ) {
    if (isConnecting || isConnected) return;

    console.log("[Realtime] âœ… startCall()", { lang, equipmentState });

    // ì½œë°± ì´ˆê¸°í™”
    messageCallbackRef.current = callbacks || {};
    currentResponseRef.current = "";
    lastAssistantTextRef.current = "";
    callStartTimeRef.current = Date.now(); // â­ 1ì´ˆ ë¬´ì‹œ ì‹œì‘
    console.log("[Realtime] â³ Ignoring STT for first 1000ms");

    setIsConnecting(true);

    try {
      const API_BASE_URL = (import.meta.env.VITE_API_URL || "").trim();
      if (!API_BASE_URL) throw new Error("VITE_API_URL is not set");

      // -----------------------
      // 1. Realtime Session ë°œê¸‰
      // -----------------------
      const params = new URLSearchParams();
      if (equipmentState) {
        for (const [k, v] of Object.entries(equipmentState)) {
          params.append(k, String(v));
        }
      }

      const sessionUrl = `${API_BASE_URL}/api/session/${lang}${
        params.toString() ? `?${params.toString()}` : ""
      }`;

      const sessionRes = await fetch(sessionUrl);
      if (!sessionRes.ok)
        throw new Error(
          `Session fetch failed: ${
            sessionRes.status
          } ${await sessionRes.text()}`
        );

      const sessionData = await sessionRes.json();
      const EPHEMERAL_KEY = sessionData?.client_secret?.value;
      if (!EPHEMERAL_KEY)
        throw new Error("No ephemeral key received from /api/session");

      // -----------------------
      // 2. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼
      // -----------------------
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 48000,
          channelCount: 1,
        },
      });
      streamRef.current = stream;

      // -----------------------
      // 3. PeerConnection
      // -----------------------
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
      });
      peerRef.current = pc;

      stream.getTracks().forEach((track) => pc.addTrack(track, stream));

      // 4. ìˆ˜ì‹  ì˜¤ë””ì˜¤
      const audio = new Audio();
      audio.autoplay = true;
      audioRef.current = audio;

      pc.ontrack = (event) => {
        const [remoteStream] = event.streams;
        if (remoteStream) audio.srcObject = remoteStream;
      };

      pc.onconnectionstatechange = () => {
        if (
          pc.connectionState === "failed" ||
          pc.connectionState === "disconnected" ||
          pc.connectionState === "closed"
        ) {
          endCall();
        }
      };

      // -----------------------
      // 5. DataChannel
      // -----------------------
      const channel = pc.createDataChannel("response");
      channelRef.current = channel;

      channel.onopen = () => {
        channel.send(JSON.stringify({ type: "response.create" }));
      };

      channel.onmessage = (ev) => {
        try {
          const msg = JSON.parse(ev.data);

          // ğŸ”¹ AI ìŒì„± â†’ í…ìŠ¤íŠ¸ ë¸íƒ€
          if (msg.type === "response.audio_transcript.delta") {
            currentResponseRef.current += msg.delta ?? "";
          }

          // ğŸ”¹ AI ìŒì„± â†’ ìµœì¢… í…ìŠ¤íŠ¸
          if (msg.type === "response.audio_transcript.done") {
            const full = currentResponseRef.current.trim();
            currentResponseRef.current = "";
            if (!full) return;

            const match = full.match(/\[EQUIPMENT_DETAIL:(\w+)\]/);
            const equipId = match?.[1] ?? null;

            const clean = full.replace(/\[EQUIPMENT_DETAIL:\w+\]/g, "").trim();
            lastAssistantTextRef.current = clean;

            messageCallbackRef.current.onAIMessage?.(clean);
            if (equipId)
              messageCallbackRef.current.onEquipmentDetail?.(equipId);
          }

          // ğŸ”¹ ì‚¬ìš©ì STT
          if (
            msg.type === "conversation.item.input_audio_transcription.completed"
          ) {
            const text = msg.transcript?.trim();
            if (!text) return;

            // â­ 1) ì²« 1ì´ˆ ë¬´ì¡°ê±´ ë¬´ì‹œ
            const elapsed = Date.now() - callStartTimeRef.current;
            if (elapsed < 1000) {
              console.log("[STT] â± Ignored (first 1s):", text);
              return;
            }

            // â­ 2) Silence Gate
            if (isSilence(text)) {
              console.log("[STT] âŒ Ignored (silence/noise):", text);
              return;
            }

            // â­ 3) ì—ì½”/ì¶”ì„ìƒˆ í•„í„°
            if (shouldIgnoreTranscript(text, lastAssistantTextRef.current)) {
              console.log("[STT] âŒ Ignored (heuristic):", text);
              return;
            }

            // ìµœì¢… í†µê³¼
            console.log("[STT] ğŸ¤ User:", text);
            messageCallbackRef.current.onUserMessage?.(text);
          }
        } catch (err) {
          console.error("[Realtime] onmessage parse error:", err);
        }
      };

      // -----------------------
      // 6. SDP Offer â†” Answer
      // -----------------------
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      const model = "gpt-4o-realtime-preview-2025-06-03";

      const sdpRes = await fetch(
        `https://api.openai.com/v1/realtime?model=${model}`,
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${EPHEMERAL_KEY}`,
            "Content-Type": "application/sdp",
          },
          body: offer.sdp ?? "",
        }
      );

      const answerSdp = await sdpRes.text();
      await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

      setIsConnected(true);
      setIsConnecting(false);
    } catch (err) {
      console.error("[Realtime] startCall error:", err);
      endCall();
    } finally {
      setIsConnecting(false);
    }
  }

  // --------------------------
  // endCall
  // --------------------------
  function endCall() {
    console.log("[Realtime] ğŸ”» endCall()");

    try {
      channelRef.current?.close();
      peerRef.current?.getSenders().forEach((s) => s.track?.stop());
      peerRef.current?.close();

      audioRef.current?.pause();
      if (audioRef.current) audioRef.current.srcObject = null;

      streamRef.current?.getTracks().forEach((t) => t.stop());
    } catch {}

    channelRef.current = null;
    peerRef.current = null;
    audioRef.current = null;
    streamRef.current = null;

    setIsConnected(false);
    setIsConnecting(false);
  }

  return { startCall, endCall, isConnecting, isConnected };
}
